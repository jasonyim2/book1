{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12417, 73)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Lasso_select_ERP.csv')   \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2 shape: (6208, 132)\n",
      "X_test2 shape: (6209, 132)\n"
     ]
    }
   ],
   "source": [
    "# SimpleInputer의 add_indicator 옵션을 제거한 버전.\n",
    "\n",
    "data = df.drop(['EBizSystem2'], axis=1)   # 타겟변수를 제외한 입력변수를 data에 저장.\n",
    "target = df['EBizSystem2']                # 타겟변수만 target에 저장.\n",
    "\n",
    "# 50:50 data partition.\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    data, target, test_size=0.5, random_state=42)   # test_size=0.5임에 주의. \n",
    "\n",
    "# interval 변수의 null value를 평균(mean)으로 impute. \n",
    "from sklearn.impute import SimpleImputer\n",
    "imp= SimpleImputer(strategy = 'mean')  \n",
    "X_train2= imp.fit_transform(X_train) \n",
    "X_test2= imp.fit_transform(X_test)   # X_train과 and X_test 둘 다 imputation 적용해야 함에 유의.\n",
    "\n",
    "print(\"X_train2 shape:\", X_train2.shape) \n",
    "print(\"X_test2 shape:\", X_test2.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network 모델 (Default 모델).\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "clf_mlp = MLPClassifier(max_iter = 500, random_state = 0)\n",
    "clf_mlp.fit(X_train2, y_train)\n",
    "pred = clf_mlp.predict(X_test2)  # 학습된 Classifier로 테스트 데이터셋 자료이용해서 타겟변수 예측값 생성.\n",
    "accuracy = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV max accuracy:0.66640\n",
      "GridSearchCV best parameter: {'activation': 'relu', 'alpha': 1, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'solver':['lbfgs'], 'alpha':[1],\\\n",
    "         'activation':['tanh','relu', 'logistic']}\n",
    "\n",
    "grid_mlp = GridSearchCV(clf_mlp, param_grid=params, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_mlp.fit(X_train2, y_train)\n",
    "\n",
    "print(\"GridSearchCV max accuracy:{:.5f}\".format(grid_mlp.best_score_))\n",
    "print(\"GridSearchCV best parameter:\", (grid_mlp.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV max accuracy:0.71746\n",
      "GridSearchCV best parameter: {'activation': 'logistic', 'alpha': 1, 'max_iter': 1000, 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'solver':['sgd'], 'alpha':[1], 'max_iter':[1000],\\\n",
    "         'activation':['tanh','relu', 'logistic']}\n",
    "\n",
    "grid_mlp = GridSearchCV(clf_mlp, param_grid=params, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_mlp.fit(X_train2, y_train)\n",
    "\n",
    "print(\"GridSearchCV max accuracy:{:.5f}\".format(grid_mlp.best_score_))\n",
    "print(\"GridSearchCV best parameter:\", (grid_mlp.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV max accuracy:0.71939\n",
      "GridSearchCV best parameter: {'activation': 'logistic', 'alpha': 1, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'solver':['adam'], 'alpha':[1],\\\n",
    "         'activation':['tanh','relu', 'logistic']}\n",
    "\n",
    "grid_mlp = GridSearchCV(clf_mlp, param_grid=params, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_mlp.fit(X_train2, y_train)\n",
    "\n",
    "print(\"GridSearchCV max accuracy:{:.5f}\".format(grid_mlp.best_score_))\n",
    "print(\"GridSearchCV best parameter:\", (grid_mlp.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV max accuracy:0.72245\n",
      "GridSearchCV best parameter: {'activation': 'logistic', 'alpha': 0.0001, 'max_iter': 1000, 'solver': 'sgd'}\n",
      "Runtime of the program is 294.8421320915222\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'solver':['adam','lbfgs', 'sgd'], 'alpha':[0.0001, 0.001, 0.01, 0.1, 1],\\\n",
    "          'max_iter':[1000],'activation':['logistic','relu']}\n",
    "\n",
    "grid_mlp = GridSearchCV(clf_mlp, param_grid=params, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_mlp.fit(X_train2, y_train)\n",
    "\n",
    "print(\"GridSearchCV max accuracy:{:.5f}\".format(grid_mlp.best_score_))\n",
    "print(\"GridSearchCV best parameter:\", (grid_mlp.best_params_)) \n",
    "\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:0.72524\n",
      "ROC AUC on test set:0.78719\n"
     ]
    }
   ],
   "source": [
    "best_clf = grid_mlp.best_estimator_\n",
    "pred = best_clf.predict(X_test2)\n",
    "print(\"Accuracy on test set:{:.5f}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test,best_clf.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
