{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C.7.16 앙상블 보팅 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 두 줄 코딩 즉 xgboost와 lightgbm 설치 구문 중 하나라도 주피터 노트북에서 설치에러 발생시에는\n",
    "# 구글 코랩에서 이 ipynb 파일을 열고 실행할 것을 추천함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그 때 2014DC2.csv 등의 데이터 파일을 구글 드라이브에 업로딩하고 이를 구글 코랩에서 불러오기 위해서는 \n",
    "# 책 본문 4.7.6의 텐서플로 케라스 절의 초반 안내 사항 준수 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\jason\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.1-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jason\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\jason\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\jason\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jason\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jason\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트리 계열 보팅 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12417, 75)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('2014DC2.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['EBizSystem2'], axis=1)   # 타겟변수를 제외한 변수만 data 데이터프레임에 저장\n",
    "target = df['EBizSystem2']                # 타겟변수만 target 데이터프레임에 저장\n",
    "\n",
    "# 50:50 Data partition\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    data, target, test_size=0.5, random_state=42)   # test_size=0.3임에 주의 \n",
    "\n",
    "# interval 변수의 null value를 평균(mean)으로 impute. \n",
    "from sklearn.impute import SimpleImputer\n",
    "imp= SimpleImputer(strategy = 'mean')  \n",
    "X_train2= imp.fit_transform(X_train) \n",
    "X_test2= imp.fit_transform(X_test)   # X_train과 and X_test 둘 다 imputation 적용해야 함에 유의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6개 트리 계열 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.68626\n",
      "RandomForestClassifier 0.72041\n",
      "BaggingClassifier 0.71477\n",
      "GradientBoostingClassifier 0.72298\n",
      "[18:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72653\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting for all 6 tree-based models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=4, random_state=0) \n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=19, random_state=0) \n",
    "clf_bg = BaggingClassifier(DecisionTreeClassifier(max_depth=9,random_state=0),\n",
    "                           n_estimators=200,random_state=0) \n",
    "clf_gb = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "                                    random_state=0)\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('tree', clf_tree),('rf', clf_rf),('bg', clf_bg),\n",
    "                                          ('gb', clf_gb),('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='hard') \n",
    "                                       # voting='hard'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_tree, clf_rf, clf_bg, clf_gb, clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.68626\n",
      "RandomForestClassifier 0.72041\n",
      "BaggingClassifier 0.71477\n",
      "GradientBoostingClassifier 0.72298\n",
      "[18:56:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72910\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting for all 6 tree-based models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=4, random_state=0) \n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=19, random_state=0) \n",
    "clf_bg = BaggingClassifier(DecisionTreeClassifier(max_depth=9,random_state=0),\n",
    "                           n_estimators=200,random_state=0) \n",
    "clf_gb = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "                                    random_state=0)\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('tree', clf_tree),('rf', clf_rf),('bg', clf_bg),\n",
    "                                          ('gb', clf_gb),('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='soft') \n",
    "                                       # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_tree, clf_rf, clf_bg, clf_gb, clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.78854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도 상위 4개 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.72041\n",
      "GradientBoostingClassifier 0.72298\n",
      "[19:01:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72814\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting\n",
    "# 상위 4개 모델만 앙상블 \n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=19, random_state=0) \n",
    "clf_gb = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "                                    random_state=0)\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('gb', clf_gb),('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='hard') \n",
    "                              # voting='hard'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_rf, clf_gb, clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.72041\n",
      "GradientBoostingClassifier 0.72298\n",
      "[19:02:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72669\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting\n",
    "# 상위 4개 모델만 앙상블 \n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=19, random_state=0) \n",
    "clf_gb = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "                                    random_state=0)\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('gb', clf_gb),('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='soft') \n",
    "                              # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_rf, clf_gb, clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도 상위 3개 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier 0.72298\n",
      "[18:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72814\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting\n",
    "# Accuracy 0.72 이상인 3개 모델만 앙상블 \n",
    "\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "                                    random_state=0)\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('gb', clf_gb),('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='hard') \n",
    "                              # voting='hard'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_gb, clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier 0.72298\n",
      "[18:54:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72669\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting\n",
    "# Accuracy 0.72 이상인 3개 모델만 앙상블 \n",
    "\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=0.1,\n",
    "                                    random_state=0)\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('gb', clf_gb),('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='soft') \n",
    "                              # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_gb, clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도 상위 2개 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72588\n"
     ]
    }
   ],
   "source": [
    "# 하드 보팅\n",
    "# 정확도가 가장 높은 2개 모델만 앙상블\n",
    "\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='hard') \n",
    "                              # voting='hard'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:04:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier 0.72604\n",
      "LGBMClassifier 0.72878\n",
      "VotingClassifier 0.72765\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅\n",
    "# 정확도가 가장 높은 2개 모델만 앙상블\n",
    "\n",
    "clf_xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=4, n_estimators=200, subsample=0.8, random_state=0)\n",
    "clf_lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.05, max_depth=10,\n",
    "                         min_child_weight=2, n_estimators=200, subsample=0.4, random_state=0)\n",
    "clf_voting = VotingClassifier(estimators=[('xgb',clf_xgb),('lgb',clf_lgb)],\n",
    "                              n_jobs=-1, voting='soft') \n",
    "                              # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_xgb, clf_lgb, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.78926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 모델에 쓰인 데이터셋 활용 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12417, 193)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('2014DC2_dummy_indicator_friendly.csv')   \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2 shape: (6208, 214)\n",
      "X_test2 shape: (6209, 214)\n"
     ]
    }
   ],
   "source": [
    "# Imputation indicator가 생성됨에 주의\n",
    "\n",
    "data = df.drop(['EBizSystem2'], axis=1)   # 타겟변수를 제외한 변수만 data 데이터프레임에 저장\n",
    "target = df['EBizSystem2']                # 타겟변수만 target 데이터프레임에 저장\n",
    "\n",
    "# 50:50 data partition.\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    data, target, test_size=0.5, random_state=42)   # test_size=0.5임에 주의 \n",
    "\n",
    "# interval 변수의 null value를 평균(mean)으로 impute 및 add_indicator 포함 \n",
    "from sklearn.impute import SimpleImputer\n",
    "imp= SimpleImputer(strategy = 'mean', add_indicator=True)  \n",
    "X_train2= imp.fit_transform(X_train) \n",
    "X_test2= imp.fit_transform(X_test)   # X_train과 and X_test 둘 다 imputation 적용해야 함에 유의\n",
    "\n",
    "print(\"X_train2 shape:\", X_train2.shape) \n",
    "print(\"X_test2 shape:\", X_test2.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6개 모델 모두 사용한 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.72975\n",
      "LogisticRegression 0.73120\n",
      "LogisticRegression 0.73265\n",
      "MLPClassifier 0.73104\n",
      "KNeighborsClassifier 0.68385\n",
      "SVC 0.72991\n",
      "VotingClassifier 0.73152\n",
      "Runtime of the program is 438.55333948135376\n"
     ]
    }
   ],
   "source": [
    "# 하드 보팅\n",
    "# 로지스틱 회귀, 릿지, 라소, 신경망, KNN, SVM 모델을 앙상블\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clf_lr = LogisticRegression(solver='saga',penalty='none',max_iter=10000,random_state=0)\n",
    "clf_rg = LogisticRegression(solver='lbfgs',penalty='l2',max_iter=10000,random_state=0)\n",
    "clf_ls = LogisticRegression(penalty='l1',solver='liblinear',C=0.1,random_state=0)\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=0.1,max_iter=1000,\n",
    "                        hidden_layer_sizes = (100, 100), random_state=0)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=39)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0)\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('lr', clf_lr),('rg',clf_rg),('ls', clf_ls),('mlp', clf_mlp),\n",
    "                                          ('knn', clf_knn),('svm', clf_svm)],\n",
    "                              n_jobs=-1, voting='hard') # voting='hard'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_lr, clf_rg, clf_ls, clf_mlp, clf_knn, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.72975\n",
      "LogisticRegression 0.73120\n",
      "LogisticRegression 0.73265\n",
      "MLPClassifier 0.73104\n",
      "KNeighborsClassifier 0.68385\n",
      "SVC 0.72991\n",
      "VotingClassifier 0.73313\n",
      "Runtime of the program is 403.1785202026367\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅\n",
    "# 로지스틱 회귀, 릿지, 라소, 신경망, KNN, SVM 모델을 앙상블\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clf_lr = LogisticRegression(solver='saga',penalty='none',max_iter=10000,random_state=0)\n",
    "clf_rg = LogisticRegression(solver='lbfgs',penalty='l2',max_iter=10000,random_state=0)\n",
    "clf_ls = LogisticRegression(penalty='l1',solver='liblinear',C=0.1,random_state=0)\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=0.1,max_iter=1000,\n",
    "                        hidden_layer_sizes = (100, 100), random_state=0)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=39)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0, probability=True) # probability=True 구문 추가\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('lr', clf_lr),('rg',clf_rg),('ls', clf_ls),('mlp', clf_mlp),\n",
    "                                          ('knn', clf_knn),('svm', clf_svm)],\n",
    "                              n_jobs=-1, voting='soft') # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_lr, clf_rg, clf_ls, clf_mlp, clf_knn, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5개 모델 모두 사용한 앙상블 (현저히 성능이 떨어지는 KNN 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.72975\n",
      "LogisticRegression 0.73120\n",
      "LogisticRegression 0.73265\n",
      "MLPClassifier 0.73104\n",
      "SVC 0.72991\n",
      "VotingClassifier 0.73458\n",
      "Runtime of the program is 867.9558868408203\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅\n",
    "# KNN 모델을 제외한 5개 모델, 즉 로지스틱 회귀, 릿지, 라소, 신경망, SVM 모델을 앙상블\n",
    "\n",
    "clf_lr = LogisticRegression(solver='saga',penalty='none',max_iter=10000,random_state=0)\n",
    "clf_rg = LogisticRegression(solver='lbfgs',penalty='l2',max_iter=10000,random_state=0)\n",
    "clf_ls = LogisticRegression(penalty='l1',solver='liblinear',C=0.1,random_state=0)\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=0.1,max_iter=1000,\n",
    "                        hidden_layer_sizes = (100, 100), random_state=0)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0, probability=True) # probability=True 구문 추가\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('lr', clf_lr),('rg',clf_rg),('ls', clf_ls),('mlp', clf_mlp),\n",
    "                                          ('svm', clf_svm)],\n",
    "                              n_jobs=-1, voting='soft') # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_lr, clf_rg, clf_ls, clf_mlp, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위 4개 모델을 사용한 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.73120\n",
      "LogisticRegression 0.73265\n",
      "MLPClassifier 0.73104\n",
      "SVC 0.72991\n",
      "VotingClassifier 0.73361\n",
      "Runtime of the program is 4587.861080169678\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅\n",
    "# 상위 4개 모델, 즉 릿지, 라소, 신경망, SVM 모델을 앙상블\n",
    "\n",
    "clf_rg = LogisticRegression(solver='lbfgs',penalty='l2',max_iter=10000,random_state=0)\n",
    "clf_ls = LogisticRegression(penalty='l1',solver='liblinear',C=0.1,random_state=0)\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=0.1,max_iter=1000,\n",
    "                        hidden_layer_sizes = (100, 100), random_state=0)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0, probability=True) # probability=True 구문 추가\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('rg',clf_rg),('ls', clf_ls),('mlp', clf_mlp),\n",
    "                                          ('svm', clf_svm)],\n",
    "                              n_jobs=-1, voting='soft') # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_rg, clf_ls, clf_mlp, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위 3개 모델을 사용한 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.73120\n",
      "LogisticRegression 0.73265\n",
      "MLPClassifier 0.73104\n",
      "VotingClassifier 0.73377\n",
      "Runtime of the program is 4786.462224721909\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅\n",
    "# 상위 3개 모델, 즉 릿지, 라소, 신경망 모델을 앙상블\n",
    "\n",
    "clf_rg = LogisticRegression(solver='lbfgs',penalty='l2',max_iter=10000,random_state=0)\n",
    "clf_ls = LogisticRegression(penalty='l1',solver='liblinear',C=0.1,random_state=0)\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=0.1,max_iter=1000,\n",
    "                        hidden_layer_sizes = (100, 100), random_state=0)\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('rg',clf_rg),('ls', clf_ls),('mlp', clf_mlp)],\n",
    "                              n_jobs=-1, voting='soft') # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_rg, clf_ls, clf_mlp, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위 2개 모델을 사용한 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.73120\n",
      "LogisticRegression 0.73265\n",
      "VotingClassifier 0.73603\n",
      "Runtime of the program is 5797.99852180481\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅\n",
    "# 상위 2개 모델, 즉 릿지와 라소 모델을 앙상블\n",
    "\n",
    "clf_rg = LogisticRegression(solver='lbfgs',penalty='l2',max_iter=10000,random_state=0)\n",
    "clf_ls = LogisticRegression(penalty='l1',solver='liblinear',C=0.1,random_state=0)\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('rg', clf_rg),('ls', clf_ls)],\n",
    "                              n_jobs=-1, voting='soft') # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_rg, clf_ls, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.79220\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라소 모델에 의해 생성된 데이터셋 활용 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12417, 73)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Lasso_select_ERP.csv')   \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2 shape: (6208, 72)\n",
      "X_test2 shape: (6209, 72)\n"
     ]
    }
   ],
   "source": [
    "# SimpleInputer의 add_indicator 옵션을 제거한 버전\n",
    "\n",
    "data = df.drop(['EBizSystem2'], axis=1) # 타겟변수를 제외한 변수만 data 데이터프레임에 저장\n",
    "target = df['EBizSystem2']                # 타겟변수만 target 데이터프레임에 저장\n",
    "\n",
    "# 50:50 data partition.\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    data, target, test_size=0.5, random_state=42)   # test_size=0.5임에 주의 \n",
    "\n",
    "# interval 변수의 null value를 평균(mean)으로 impute \n",
    "from sklearn.impute import SimpleImputer\n",
    "imp= SimpleImputer(strategy = 'mean')  \n",
    "X_train2= imp.fit_transform(X_train) \n",
    "X_test2= imp.fit_transform(X_test)   # X_train과 and X_test 둘 다 imputation 적용해야 함에 유의\n",
    "\n",
    "print(\"X_train2 shape:\", X_train2.shape) \n",
    "print(\"X_test2 shape:\", X_test2.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라소 변수 선택 후 후속 3개 모델 모두 사용한 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.72411\n",
      "KNeighborsClassifier 0.68578\n",
      "SVC 0.73297\n",
      "VotingClassifier 0.72701\n",
      "Runtime of the program is 53.437153339385986\n"
     ]
    }
   ],
   "source": [
    "# 하드 보팅 \n",
    "# 신경망, KNN, SVM 모델을 사용한 앙상블\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=1,max_iter=1000,\n",
    "                        random_state=0)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=35)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0)\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('mlp', clf_mlp),('knn', clf_knn),\n",
    "                                          ('svm', clf_svm)], n_jobs=-1, voting='hard') \n",
    "                                                                        # voting='hard'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_mlp, clf_knn, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba is not available when voting='hard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.72411\n",
      "KNeighborsClassifier 0.68578\n",
      "SVC 0.73297\n",
      "VotingClassifier 0.72492\n",
      "Runtime of the program is 64.52883410453796\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 \n",
    "# 신경망, KNN, SVM 모델을 사용한 앙상블\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=1, max_iter=1000,\n",
    "                        random_state=0)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=35)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0, probability=True) # probability=True 에 주의\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('mlp', clf_mlp),('knn', clf_knn),\n",
    "                                          ('svm', clf_svm)], n_jobs=-1, voting='soft')\n",
    "                                                                        # voting='soft'에 주의\n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_mlp, clf_knn, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.78267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라소 변수 선택 후 후속 2개 모델만 모두 사용한 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.72411\n",
      "SVC 0.73297\n",
      "VotingClassifier 0.72765\n",
      "Runtime of the program is 46.67180562019348\n"
     ]
    }
   ],
   "source": [
    "# 하드 보팅 \n",
    "# KNN을 제외한 신경망, SVM 모델을 사용한 앙상블\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=1,max_iter=1000,\n",
    "                        random_state=0)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0)\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[('mlp', clf_mlp),('svm', clf_svm)], \n",
    "                              n_jobs=-1, voting='hard') \n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_mlp, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba is not available when voting='hard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.72411\n",
      "SVC 0.73297\n",
      "VotingClassifier 0.73007\n",
      "Runtime of the program is 95.35595488548279\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 \n",
    "# KNN을 제외한 신경망, SVM 모델을 사용한 앙상블\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clf_mlp = MLPClassifier(activation='logistic',solver='sgd', alpha=1,max_iter=1000,\n",
    "                        random_state=0)\n",
    "clf_svm = SVC(kernel='linear', C=0.01, random_state=0, probability=True) # probability=True 에 주의\n",
    "clf_voting = VotingClassifier(estimators=[('mlp', clf_mlp),('svm', clf_svm)],\n",
    "                              n_jobs=-1, voting='soft') \n",
    "clf_voting.fit(X_train2, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "for clf in(clf_mlp, clf_svm, clf_voting):\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "    print (clf.__class__.__name__, \"{:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:0.78758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ROC_AUC = roc_auc_score(y_test, clf_voting.predict_proba(X_test2)[:, 1])\n",
    "print(\"ROC AUC on test set:{:.5f}\".format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Classifier로 테스트 데이터셋 자료이용해서 타겟변수 예측값 생성.\n",
    "pred = clf_voting.predict(X_test2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_arr = y_test.to_numpy()\n",
    "y_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_test  pred\n",
       "0        0     0\n",
       "1        1     0\n",
       "2        0     1\n",
       "3        0     0\n",
       "4        1     0\n",
       "5        0     0\n",
       "6        1     1\n",
       "7        1     1\n",
       "8        1     1\n",
       "9        0     1\n",
       "10       1     1\n",
       "11       0     0\n",
       "12       0     0\n",
       "13       0     0\n",
       "14       0     0\n",
       "15       0     0\n",
       "16       0     0\n",
       "17       1     1\n",
       "18       0     1\n",
       "19       1     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison = pd.DataFrame({'y_test': y_test_arr, 'pred': pred})\n",
    "df_comparison.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset2</th>\n",
       "      <th>Asset7</th>\n",
       "      <th>Asset7_ind</th>\n",
       "      <th>Asset9</th>\n",
       "      <th>Asset9_ind</th>\n",
       "      <th>B2B_purchase1</th>\n",
       "      <th>B2B_purchase1_ind</th>\n",
       "      <th>Capital1</th>\n",
       "      <th>CapitalRatio1</th>\n",
       "      <th>Compensation1_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>TAssetC1</th>\n",
       "      <th>TAssetC2</th>\n",
       "      <th>TAssetC3</th>\n",
       "      <th>TAssetC4</th>\n",
       "      <th>TAssetC5</th>\n",
       "      <th>TAssetC6</th>\n",
       "      <th>TradeMark1</th>\n",
       "      <th>emp6</th>\n",
       "      <th>emp66</th>\n",
       "      <th>emp66_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.006695</td>\n",
       "      <td>7.682482</td>\n",
       "      <td>0</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0</td>\n",
       "      <td>9.164296</td>\n",
       "      <td>0</td>\n",
       "      <td>7.273093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.638568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.769670</td>\n",
       "      <td>5.899897</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9.040145</td>\n",
       "      <td>0</td>\n",
       "      <td>9.378732</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Asset2    Asset7  Asset7_ind    Asset9  Asset9_ind  B2B_purchase1  \\\n",
       "0  7.006695  7.682482           0  4.110874           0       9.164296   \n",
       "1  6.638568       NaN           1  5.010635           0            NaN   \n",
       "2  9.769670  5.899897           0       NaN           1       9.040145   \n",
       "\n",
       "   B2B_purchase1_ind  Capital1  CapitalRatio1  Compensation1_4.0  ...  \\\n",
       "0                  0  7.273093       0.000000                  0  ...   \n",
       "1                  1  0.000000       0.000000                  0  ...   \n",
       "2                  0  9.378732       4.615121                  0  ...   \n",
       "\n",
       "   TAssetC1  TAssetC2  TAssetC3  TAssetC4  TAssetC5  TAssetC6  TradeMark1  \\\n",
       "0  3.555348   1.94591       0.0       0.0       0.0  0.000000    1.386294   \n",
       "1  0.000000   0.00000       0.0       0.0       0.0  0.000000    1.791759   \n",
       "2  4.043051   0.00000       0.0       0.0       0.0  3.044522    0.000000   \n",
       "\n",
       "       emp6  emp66  emp66_ind  \n",
       "0  2.639057    0.0          0  \n",
       "1  2.564949    NaN          1  \n",
       "2  3.044522    0.0          0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 인덱스를 삭제하고 새로운 인덱스로 리셋\n",
    "X_test.reset_index(drop=True).head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset2</th>\n",
       "      <th>Asset7</th>\n",
       "      <th>Asset7_ind</th>\n",
       "      <th>Asset9</th>\n",
       "      <th>Asset9_ind</th>\n",
       "      <th>B2B_purchase1</th>\n",
       "      <th>B2B_purchase1_ind</th>\n",
       "      <th>Capital1</th>\n",
       "      <th>CapitalRatio1</th>\n",
       "      <th>Compensation1_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>TAssetC3</th>\n",
       "      <th>TAssetC4</th>\n",
       "      <th>TAssetC5</th>\n",
       "      <th>TAssetC6</th>\n",
       "      <th>TradeMark1</th>\n",
       "      <th>emp6</th>\n",
       "      <th>emp66</th>\n",
       "      <th>emp66_ind</th>\n",
       "      <th>y_test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.006695</td>\n",
       "      <td>7.682482</td>\n",
       "      <td>0</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0</td>\n",
       "      <td>9.164296</td>\n",
       "      <td>0</td>\n",
       "      <td>7.273093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.638568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.769670</td>\n",
       "      <td>5.899897</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9.040145</td>\n",
       "      <td>0</td>\n",
       "      <td>9.378732</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.128585</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8.058644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.307953</td>\n",
       "      <td>5.446737</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8.371474</td>\n",
       "      <td>0</td>\n",
       "      <td>8.652074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Asset2    Asset7  Asset7_ind    Asset9  Asset9_ind  B2B_purchase1  \\\n",
       "0  7.006695  7.682482           0  4.110874           0       9.164296   \n",
       "1  6.638568       NaN           1  5.010635           0            NaN   \n",
       "2  9.769670  5.899897           0       NaN           1       9.040145   \n",
       "3  8.128585  7.344719           0  1.945910           0            NaN   \n",
       "4  8.307953  5.446737           0       NaN           1       8.371474   \n",
       "\n",
       "   B2B_purchase1_ind  Capital1  CapitalRatio1  Compensation1_4.0  ...  \\\n",
       "0                  0  7.273093       0.000000                  0  ...   \n",
       "1                  1  0.000000       0.000000                  0  ...   \n",
       "2                  0  9.378732       4.615121                  0  ...   \n",
       "3                  1  8.058644       0.000000                  0  ...   \n",
       "4                  0  8.652074       0.000000                  0  ...   \n",
       "\n",
       "   TAssetC3  TAssetC4  TAssetC5  TAssetC6  TradeMark1      emp6  emp66  \\\n",
       "0       0.0       0.0       0.0  0.000000    1.386294  2.639057    0.0   \n",
       "1       0.0       0.0       0.0  0.000000    1.791759  2.564949    NaN   \n",
       "2       0.0       0.0       0.0  3.044522    0.000000  3.044522    0.0   \n",
       "3       0.0       0.0       0.0  3.332205    0.000000  2.833213    NaN   \n",
       "4       0.0       0.0       0.0  0.000000    0.000000  1.098612    0.0   \n",
       "\n",
       "   emp66_ind  y_test  pred  \n",
       "0          0       0     0  \n",
       "1          1       1     0  \n",
       "2          0       0     1  \n",
       "3          1       0     0  \n",
       "4          0       1     0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu = pd.concat([X_test.reset_index(drop=True), df_comparison], axis=1)\n",
    "dfu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
